{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "451160b9",
   "metadata": {},
   "source": [
    "# Vanishing Point Detection  (_Canny + Probabilistic Hough Transform + RANSAC_)\n",
    "\n",
    "Classical but still very effective approach for one-point perspective scenes.Example:\n",
    "- roads\n",
    "- railways\n",
    "- corridors\n",
    "- architecture\n",
    "\n",
    "**Pipeline overview:**  \n",
    "1. Grayscale + strong edge detection (_Canny_)  \n",
    "2. Line segment detection (_HoughLinesP_)  \n",
    "3. Robust vanishing point estimation via `RANSAC` on line intersections  \n",
    "\n",
    "**Still very useful when you need:** \n",
    "• interpretable results  \n",
    "• low compute / no deep learning  \n",
    "• good initialization for `SLAM` / `calibration` / `3D reconstruction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a31c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tools.tools import LearnTools\n",
    "\n",
    "learn_tools = LearnTools()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88b066c",
   "metadata": {},
   "source": [
    "## 1. Load & Prepare Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894ddb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Image form Image URLs\n",
    "\n",
    "# img_url = \"https://images.unsplash.com/photo-1506905925346-21bda4d32df4\"\n",
    "img_url = \"https://i.ibb.co.com/BVSYcmyY/joey-kyber-GPxgi4-J82-E4-unsplash.jpg\"\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists(\"testImage.jpg\"):\n",
    "    image = cv2.imread(\"testImage.jpg\")\n",
    "else:\n",
    "    pil_image = await learn_tools.get_image(\n",
    "            img_url=img_url,\n",
    "            padding=0\n",
    "        )\n",
    "    pil_image.save(\"testImage.jpg\", \"JPEG\")\n",
    "    image = learn_tools.pil_to_cv2(pil_image=pil_image)\n",
    "\n",
    "# Convert to grayscale (Equalization is typically performed on single channels)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "learn_tools.show_multiple_images(\n",
    "        image_plotting_data=[\n",
    "            {'title': 'Original Image', 'image': image},\n",
    "            {'title': 'Gray Image', 'image': gray, 'cmap': 'gray'}\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3950c66",
   "metadata": {},
   "source": [
    "## 2. Edge Detection (Canny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e8cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Most important parameters ───────────────────────────────────────\n",
    "CANNY_LOW    = 35\n",
    "CANNY_HIGH   = 180\n",
    "CANNY_APERTURE = 3\n",
    "\n",
    "edges = cv2.Canny(\n",
    "        image=gray,\n",
    "        threshold1 = CANNY_LOW,\n",
    "        threshold2 = CANNY_HIGH,\n",
    "        apertureSize = CANNY_APERTURE,\n",
    "        L2gradient = True\n",
    "    )\n",
    "\n",
    "\n",
    "# Display Result\n",
    "learn_tools.show_multiple_images(\n",
    "        image_plotting_data=[\n",
    "            {'title': 'Original Image', 'image': image},\n",
    "            {'title': 'Gray Image', 'image': gray, 'cmap': 'gray'},\n",
    "            {\"title\": \"Canny Edges\", \"image\": edges, \"cmap\": \"gray\"}\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620f53ce",
   "metadata": {},
   "source": [
    "## 3. Line Detection – Probabilistic Hough Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e6ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── HoughLinesP parameters ──────────────────────────────────────────\n",
    "HOUGH_RHO         = 1\n",
    "HOUGH_THETA       = np.pi / 180\n",
    "HOUGH_THRESHOLD   = 90      # min votes\n",
    "MIN_LINE_LENGTH   = 100\n",
    "MAX_LINE_GAP      = 15\n",
    "\n",
    "lines = cv2.HoughLinesP(\n",
    "        image=edges,\n",
    "        rho= HOUGH_RHO,\n",
    "        theta= HOUGH_THETA,\n",
    "        threshold= HOUGH_THRESHOLD,\n",
    "        minLineLength= MIN_LINE_LENGTH,\n",
    "        maxLineGap= MAX_LINE_GAP\n",
    "    )\n",
    "\n",
    "print(f\"Detected {len(lines) if lines is not None else 0} line segments\")\n",
    "\n",
    "# Visualization\n",
    "line_img = image.copy()\n",
    "if lines is not None:\n",
    "    for [[x1,y1,x2,y2]] in lines:\n",
    "        cv2.line(\n",
    "            img=line_img,\n",
    "            pt1=(x1,y1),\n",
    "            pt2=(x2,y2),\n",
    "            color=(0, 255, 100),\n",
    "            thickness=2,\n",
    "            lineType=cv2.LINE_AA\n",
    "        )\n",
    "\n",
    "# Display Result\n",
    "learn_tools.show_multiple_images(\n",
    "        image_plotting_data=[\n",
    "            {'title': 'Original Image', 'image': image},\n",
    "            {'title': 'Gray Image', 'image': gray, 'cmap': 'gray'},\n",
    "            {\"title\": \"Canny Edges\", \"image\": edges, \"cmap\": \"gray\"},\n",
    "            {\"title\": \"Detected Line Segments\", \"image\": line_img}\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfb5cd6",
   "metadata": {},
   "source": [
    "## 4. RANSAC-based Vanishing Point Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea354790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_to_homogeneous(x1,y1,x2,y2):\n",
    "    \"\"\" Line in homogeneous form: ax + by + c = 0 \"\"\"\n",
    "    a = y1 - y2\n",
    "    b = x2 - x1\n",
    "    c = x1*y2 - x2*y1\n",
    "    return np.array([a, b, c], dtype=float)\n",
    "\n",
    "\n",
    "def intersection(l1, l2, eps=1e-8):\n",
    "    \"\"\" Intersection point of two lines in homogeneous coordinates \"\"\"\n",
    "    p = np.cross(l1, l2)\n",
    "    if abs(p[2]) < eps:\n",
    "        return None  # parallel / same line\n",
    "    return p[:2] / p[2]\n",
    "\n",
    "\n",
    "def point_line_distance(point, line):\n",
    "    \"\"\" Distance from point to line (ax+by+c=0) \"\"\"\n",
    "    x, y = point\n",
    "    a, b, c = line\n",
    "    return abs(a*x + b*y + c) / np.sqrt(a*a + b*b + 1e-10)\n",
    "\n",
    "\n",
    "# Prepare lines in normal form\n",
    "if lines is None:\n",
    "    print(\"No lines detected - cannot continue\")\n",
    "else:\n",
    "    lines_h = [line_to_homogeneous(x1,y1,x2,y2) for [[x1,y1,x2,y2]] in lines]\n",
    "\n",
    "    best_vp = None\n",
    "    best_inliers = 0\n",
    "    best_mask = None\n",
    "\n",
    "    N_ITERATIONS   = 1200\n",
    "    INLIER_TH      = 4.0       # pixels\n",
    "    MIN_INLIERS    = 15\n",
    "\n",
    "    n_lines = len(lines_h)\n",
    "\n",
    "    for _ in range(N_ITERATIONS):\n",
    "        idx = np.random.choice(n_lines, 2, replace=False)\n",
    "        l1, l2 = lines_h[idx[0]], lines_h[idx[1]]\n",
    "\n",
    "        vp_candidate = intersection(l1, l2)\n",
    "        if vp_candidate is None:\n",
    "            continue\n",
    "\n",
    "        # Count inliers\n",
    "        distances = [point_line_distance(vp_candidate, l) for l in lines_h]\n",
    "        inliers = np.array(distances) < INLIER_TH\n",
    "        count = np.sum(inliers)\n",
    "\n",
    "        if count > best_inliers:\n",
    "            best_inliers = count\n",
    "            best_vp = vp_candidate\n",
    "            best_mask = inliers\n",
    "\n",
    "    print(f\"Best model found with {best_inliers} inliers ({best_inliers/n_lines:.1%})\")\n",
    "\n",
    "    # ── Visualization ───────────────────────────────────────────────\n",
    "    result = image.copy()\n",
    "\n",
    "    # Draw all lines (faint)\n",
    "    for i, [[x1,y1,x2,y2]] in enumerate(lines):\n",
    "        color = (80,80,255) if not best_mask[i] else (0,220,50)\n",
    "        cv2.line(result, (x1,y1), (x2,y2), color, 2, cv2.LINE_AA)\n",
    "\n",
    "    if best_vp is not None:\n",
    "        x, y = map(int, best_vp)\n",
    "        # Draw big red vanishing point\n",
    "        cv2.circle(result, (x,y), 12, (255,30,30), -1, cv2.LINE_AA)\n",
    "        cv2.circle(result, (x,y), 18, (255,255,255), 3, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    # Display Result\n",
    "    learn_tools.show_multiple_images(\n",
    "        image_plotting_data=[\n",
    "            {'title': 'Original Image', 'image': image},\n",
    "            {'title': 'Gray Image', 'image': gray, 'cmap': 'gray'},\n",
    "            {\"title\": \"Canny Edges\", \"image\": edges, \"cmap\": \"gray\"},\n",
    "            {\"title\": \"Detected Line Segments\", \"image\": line_img},\n",
    "            {\"title\": f'Vanishing Point (RANSAC)  -  {best_inliers} inliers', \"image\": result}\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d85d20f",
   "metadata": {},
   "source": [
    "## Quick tuning guide\n",
    "\n",
    "| Stage          | Most sensitive parameters                          | Typical range / advice                             |\n",
    "|---------------|----------------------------------------------------|-----------------------------------------------------|\n",
    "| Canny         | low/high threshold                                 | low: 50–120, high: 120–250                         |\n",
    "| HoughP        | threshold, minLineLength, maxLineGap               | threshold 70–140, minLen 60–180, gap 8–25          |\n",
    "| RANSAC        | inlier threshold (px), nb iterations               | 3–8 pixels, 800–2500 iterations                    |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
